{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a7333fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "from argparse import ArgumentParser\n",
    "from typing import List, Any\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from rembg import remove\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9375f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_models = {0: \"SIMPLE_PINHOLE\",\n",
    "                 1: \"PINHOLE\",\n",
    "                 2: \"SIMPLE_RADIAL\",\n",
    "                 3: \"RADIAL\",\n",
    "                 4: \"OPENCV\",\n",
    "                 5: \"OPENCV_FISHEYE\",\n",
    "                 6: \"FULL_OPENCV\",\n",
    "                 7: \"FOV\",\n",
    "                 8: \"SIMPLE_RADIAL_FISHEYE\",\n",
    "                 9: \"RADIAL_FISHEYE\",\n",
    "                 10: \"THIN_PRISM_FISHEYE\"}\n",
    "\n",
    "\n",
    "def inv_trafo(trafo: np.ndarray) -> np.ndarray:\n",
    "    inverse = np.eye(4)\n",
    "    inverse[:3, :3] = trafo[:3, :3].T\n",
    "    inverse[:3, 3] = -trafo[:3, :3].T @ trafo[:3, 3]\n",
    "    return inverse\n",
    "\n",
    "\n",
    "def get_camera(cam_id: int,\n",
    "               camera_model: str,\n",
    "               width: int,\n",
    "               height: int,\n",
    "               calibration: h5py.File) -> List:\n",
    "    K = calibration[f\"N{cam_id}_rgb_K\"][:]\n",
    "    d = calibration[f\"N{cam_id}_rgb_d\"][:]\n",
    "\n",
    "    fx, fy, cx, cy, s = K[0, 0], K[1, 1], K[0, 2], K[1, 2], K[0, 1]\n",
    "    k1, k2, p1, p2, k3, k4, k5, k6 = d[0], d[1], d[2], d[3], d[4], 0, 0, 0\n",
    "\n",
    "    camera = [cam_id, camera_model, width, height, fx]\n",
    "    if camera_model == camera_models[0]:\n",
    "        camera.extend([cx, cy])\n",
    "    elif camera_model == camera_models[1]:\n",
    "        camera.extend([fy, cx, cy])\n",
    "    elif camera_model in [camera_models[2], camera_models[8]]:\n",
    "        camera.extend([cx, cy, k1])\n",
    "    elif camera_model in [camera_models[3], camera_models[9]]:\n",
    "        camera.extend([cx, cy, k1, k2])\n",
    "    elif camera_model == camera_models[4]:\n",
    "        camera.extend([fy, cx, cy, k1, k2, p1, p2])\n",
    "    elif camera_model == camera_models[5]:\n",
    "        camera.extend([fy, cx, cy, k1, k2, k3, 0])\n",
    "    elif camera_model in [camera_models[6], camera_models[10]]:\n",
    "        camera.extend([fy, cx, cy, k1, k2, p1, p2, k3, k4, k5, k6])\n",
    "    elif camera_model == camera_models[7]:\n",
    "        camera.extend([fy, cx, cy, 0])\n",
    "    else:\n",
    "        raise ValueError\n",
    "    return camera\n",
    "\n",
    "\n",
    "def get_image(cam_id: int,\n",
    "              angle: int,\n",
    "              image_counter: int,\n",
    "              data_dir: str,\n",
    "              calibration: h5py.File) -> List:\n",
    "    image_id = angle // 3 + 1\n",
    "    image_name = \"image\" + str(image_id).zfill(3) + \".jpg\"\n",
    "\n",
    "    pose_data = h5py.File(os.path.join(data_dir, \"poses\", f\"NP5_{angle}_pose.h5\"))\n",
    "    f_table_ref = pose_data[\"H_table_from_reference_camera\"][:]\n",
    "    pose_data.close()\n",
    "\n",
    "    f_rgb_ref = calibration[f\"H_N{cam_id}_from_NP5\"][:]\n",
    "    f_ref_rgb = inv_trafo(f_rgb_ref)\n",
    "    f_table_rgb = f_table_ref @ f_ref_rgb\n",
    "    f_rgb_table = inv_trafo(f_table_rgb)\n",
    "    QX, QY, QZ, QW = R.from_matrix(f_rgb_table[:3, :3]).as_quat()\n",
    "    TX, TY, TZ = f_rgb_table[:3, 3]\n",
    "\n",
    "    image = [image_counter, QW, QX, QY, QZ, TX, TY, TZ, cam_id, f\"cam{cam_id}/{image_name}\"]\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_mask(data_dir: str,\n",
    "             image_path: str,\n",
    "             pad: List[int],\n",
    "             image: np.ndarray) -> np.ndarray:\n",
    "    image_id = int(image_path.split('/')[-1].split('_')[-1].split('.')[0]) // 3 + 1\n",
    "    init_mask_path = os.path.join(data_dir, \"masks\",\n",
    "                                  image_path.split('/')[-1].replace(\".jpg\", \"_mask.pbm\"))\n",
    "    mask = np.asarray(Image.open(init_mask_path, formats=[\"PPM\"]).convert('L'), dtype=bool)\n",
    "    extend = np.argwhere(~mask)\n",
    "    _min, _max = extend.min(axis=0), extend.max(axis=0)\n",
    "    mask = np.ones_like(mask, dtype=bool)\n",
    "    mask[_min[0] - pad[0]:_max[0] + pad[1], _min[1] - pad[2]:_max[1] + pad[3]] = False\n",
    "\n",
    "    rembg_input = image[_min[0] - pad[0]:_max[0] + pad[1], _min[1] - pad[2]:_max[1] + pad[3]]\n",
    "    if args.show_bbox and image_id == 1:\n",
    "        from cv2 import imshow, waitKey, destroyAllWindows, resize\n",
    "        imshow(\"Bounding Box\", resize(rembg_input, (rembg_input.shape[1] // 2, rembg_input.shape[0] // 2)))\n",
    "        waitKey(0)\n",
    "        destroyAllWindows()\n",
    "\n",
    "    rembg_output = remove(rembg_input, alpha_matting=True, alpha_matting_erode_size=15, only_mask=True)\n",
    "\n",
    "    mask = np.zeros_like(mask, dtype=rembg_output.dtype)\n",
    "    mask[_min[0] - pad[0]:_max[0] + pad[1], _min[1] - pad[2]:_max[1] + pad[3]] = rembg_output\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebc0e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args: Any):\n",
    "    all_images_dir = os.path.join(args.data_dir, \"sfm\", \"images\")\n",
    "    all_masks_dir = all_images_dir.replace(\"images\", \"masks\")\n",
    "    colmap_dir = os.path.join(args.data_dir, \"sfm\", \"colmap\")\n",
    "    database_path = os.path.join(colmap_dir, \"database.db\")\n",
    "    camera_model_id = dict((v, k) for k, v in camera_models.items())[args.camera_model]\n",
    "    camera_model = camera_models[camera_model_id]\n",
    "    cameras = list()\n",
    "    images = list()\n",
    "\n",
    "    if args.data or (args.sparse and not os.path.isfile(database_path)):\n",
    "        data_dir = args.data_dir\n",
    "        pad = args.padding\n",
    "\n",
    "        calibration = h5py.File(os.path.join(data_dir, \"calibration.h5\"))\n",
    "        image_counter = 1\n",
    "\n",
    "        for cam_id in args.camera_ids:\n",
    "            cameras.append(get_camera(cam_id, camera_model, args.width, args.height, calibration))\n",
    "\n",
    "            image_dir = os.path.join(all_images_dir, f\"cam{cam_id}\")\n",
    "            mask_dir = image_dir.replace(\"images\", \"masks\")\n",
    "            os.makedirs(image_dir, exist_ok=True)\n",
    "            os.makedirs(mask_dir, exist_ok=True)\n",
    "\n",
    "            for angle in tqdm(np.arange(0, 360, 3), desc=f\"Processing images [camera {cam_id}/{len(args.camera_ids)}]\"):\n",
    "                image_id = angle // 3 + 1\n",
    "                image_name = \"image\" + str(image_id).zfill(3) + \".jpg\"\n",
    "\n",
    "                image_path = os.path.join(data_dir, f\"N{cam_id}_{angle}.jpg\")\n",
    "                copy_image_path = os.path.join(image_dir, image_name)\n",
    "                if not os.path.isfile(copy_image_path):\n",
    "                    shutil.copy(image_path, copy_image_path)\n",
    "\n",
    "                images.append(get_image(cam_id, angle, image_counter, data_dir, calibration))\n",
    "                image_counter += 1\n",
    "\n",
    "                depth_mask_path = os.path.join(mask_dir, image_name)\n",
    "                mask_depth = args.mask_depth and not os.path.isfile(depth_mask_path)\n",
    "\n",
    "                masked_dir = image_dir.replace(\"images\", \"masked\")\n",
    "                masked_path = os.path.join(masked_dir, image_name)\n",
    "                masked = args.masked and not os.path.isfile(masked_path)\n",
    "\n",
    "                refined_mask_path = os.path.join(mask_dir, image_name + \".png\")\n",
    "                if not os.path.isfile(refined_mask_path) or masked:\n",
    "                    pil_image = Image.open(image_path, formats=[\"JPEG\"])\n",
    "                    image = np.asarray(pil_image)\n",
    "                if not os.path.isfile(refined_mask_path) or mask_depth or masked:\n",
    "                    try:\n",
    "                        mask = np.asarray(Image.open(refined_mask_path, formats=[\"PNG\"]))\n",
    "                    except FileNotFoundError:\n",
    "                        mask = get_mask(data_dir, image_path, pad, image)\n",
    "                        Image.fromarray(mask).save(refined_mask_path)\n",
    "\n",
    "                if mask_depth:\n",
    "                    Image.fromarray(mask).save(depth_mask_path,\n",
    "                                               quality=100,\n",
    "                                               subsampling=0)\n",
    "\n",
    "                if masked:\n",
    "                    os.makedirs(masked_dir, exist_ok=True)\n",
    "                    masked_image = Image.composite(pil_image,\n",
    "                                                   Image.fromarray(np.zeros_like(image)),\n",
    "                                                   Image.fromarray(mask))\n",
    "                    masked_image.save(masked_path,\n",
    "                                      quality=100,\n",
    "                                      subsampling=0,\n",
    "                                      exif=pil_image.info[\"exif\"])\n",
    "\n",
    "        calibration.close()\n",
    "\n",
    "    sparse_dir = os.path.join(colmap_dir, \"sparse\")\n",
    "    dense_dir = os.path.join(colmap_dir, \"dense\")\n",
    "    pipeline = list()\n",
    "\n",
    "    if args.sparse or args.dense:\n",
    "        os.makedirs(colmap_dir, exist_ok=True)\n",
    "        if args.sparse or args.mask_depth:\n",
    "            sys.path.insert(0, os.path.join(args.colmap_github_dir, \"scripts\", \"python\"))\n",
    "        if args.sparse:\n",
    "            os.makedirs(sparse_dir, exist_ok=True)\n",
    "        if args.dense:\n",
    "            os.makedirs(dense_dir, exist_ok=True)\n",
    "\n",
    "    if args.sparse and not os.path.isfile(os.path.join(sparse_dir, \"database.db\")):\n",
    "        extract_features = f\"colmap feature_extractor\" \\\n",
    "                           f\" --database_path {database_path}\" \\\n",
    "                           f\" --image_path {all_images_dir}\" \\\n",
    "                           f\" --ImageReader.mask_path {all_masks_dir}\" \\\n",
    "                           f\" --ImageReader.camera_model {camera_model}\" \\\n",
    "                           f\" --ImageReader.single_camera_per_folder 1\" \\\n",
    "                           f\" --SiftExtraction.max_image_size {args.max_image_size}\" \\\n",
    "                           f\" --SiftExtraction.estimate_affine_shape {args.estimate_affine_shape}\" \\\n",
    "                           f\" --SiftExtraction.domain_size_pooling {args.domain_size_pooling}\"\n",
    "        subprocess.run(extract_features.split(' '))\n",
    "\n",
    "        from database import COLMAPDatabase, blob_to_array\n",
    "        db = COLMAPDatabase.connect(database_path)\n",
    "        rows = db.execute(\"SELECT * FROM images\")\n",
    "        db_images = list(rows)\n",
    "\n",
    "        new_images = [list()] * len(images)\n",
    "        for db_image in db_images:\n",
    "            for image in images:\n",
    "                if db_image[1] == image[-1]:\n",
    "                    image[0] = db_image[0]\n",
    "                    new_images[db_image[0] - 1] = image\n",
    "\n",
    "        assert len(db_images) == len(new_images)\n",
    "        for db_image, image in zip(db_images, new_images):\n",
    "            assert db_image[0] == image[0]\n",
    "            assert db_image[1] == image[-1]\n",
    "        db.close()\n",
    "\n",
    "        if args.update_cameras:\n",
    "            db = COLMAPDatabase.connect(database_path)\n",
    "            for camera in cameras:\n",
    "                command = f\"UPDATE cameras SET params=(?) WHERE camera_id={camera[0]}\"\n",
    "                db.execute(command, (np.array(camera[4:]).tobytes(),))\n",
    "            db.commit()\n",
    "            db.close()\n",
    "\n",
    "        db = COLMAPDatabase.connect(database_path)\n",
    "        rows = db.execute(\"SELECT * FROM cameras\")\n",
    "        db_cams = list(rows)\n",
    "\n",
    "        assert len(db_cams) == len(cameras)\n",
    "        for db_cam, cam in zip(db_cams, cameras):\n",
    "            camera_id, model, width, height, params, prior = db_cam\n",
    "            if args.update_cameras:\n",
    "                assert camera_id == cam[0]\n",
    "                assert model == camera_model_id and width == cam[2] and height == cam[3]\n",
    "            else:\n",
    "                cameras[camera_id - 1] = [camera_id,\n",
    "                                          camera_models[model],\n",
    "                                          width,\n",
    "                                          height,\n",
    "                                          *blob_to_array(params, np.float64)]\n",
    "        db.close()\n",
    "\n",
    "        with open(os.path.join(colmap_dir, \"cameras.txt\"), 'w') as outfile:\n",
    "            outfile.write(\"\\n\".join(' '.join(str(item) for item in camera) for camera in cameras))\n",
    "        with open(os.path.join(colmap_dir, \"images.txt\"), 'w') as outfile:\n",
    "            outfile.write(\"\\n\".join(' '.join(str(item) for item in image) + \"\\n\" for image in new_images) + \"\\n\")\n",
    "        open(os.path.join(colmap_dir, \"points3D.txt\"), 'a').close()\n",
    "\n",
    "        pipeline.append(f\"colmap exhaustive_matcher\"\n",
    "                        f\" --database_path {database_path}\"\n",
    "                        f\" --SiftMatching.cross_check 1\"\n",
    "                        f\" --SiftMatching.multiple_models {args.multiple_models}\"\n",
    "                        f\" --SiftMatching.guided_matching {args.guided_matching}\")\n",
    "        if not os.path.isfile(os.path.join(sparse_dir, \"points3D.bin\")):\n",
    "            pipeline.append(f\"colmap point_triangulator\"\n",
    "                            f\" --database_path {database_path}\"\n",
    "                            f\" --image_path {all_images_dir}\"\n",
    "                            f\" --input_path {colmap_dir}\"\n",
    "                            f\" --output_path {sparse_dir}\"\n",
    "                            f\" --Mapper.multiple_models {args.multiple_models}\"\n",
    "                            f\" --Mapper.max_reg_trials 5\"\n",
    "                            f\" --Mapper.tri_ignore_two_view_tracks {args.ignore_two_view_tracks}\")\n",
    "    sparse_exists = os.path.isfile(os.path.join(sparse_dir, \"points3D.bin\"))\n",
    "    sparse_will_exist = pipeline and \"point_triangulator\" in pipeline[-1]\n",
    "    if args.show_sparse and (sparse_exists or sparse_will_exist):\n",
    "        pipeline.append(f\"python {args.colmap_github_dir}/scripts/python/visualize_model.py\"\n",
    "                        f\" --input_model {os.path.join(sparse_dir)}\"\n",
    "                        f\" --input_format .bin\")\n",
    "\n",
    "    if args.dense:\n",
    "        if args.mask_depth and not os.path.isdir(os.path.join(dense_dir, \"masks\")):\n",
    "            pipeline.append(f\"colmap image_undistorter\"\n",
    "                            f\" --image_path {all_masks_dir}\"\n",
    "                            f\" --input_path {sparse_dir} \"\n",
    "                            f\" --output_path {dense_dir}\"\n",
    "                            f\" --max_image_size {args.max_depth_size}\")\n",
    "        if not os.path.isdir(os.path.join(dense_dir, \"images\")):\n",
    "            pipeline.append(f\"colmap image_undistorter\"\n",
    "                            f\" --image_path {all_images_dir}\"\n",
    "                            f\" --input_path {sparse_dir}\"\n",
    "                            f\" --output_path {dense_dir}\"\n",
    "                            f\" --max_image_size {args.max_depth_size}\")\n",
    "        pipeline.append(f\"colmap patch_match_stereo\"\n",
    "                        f\" --workspace_path {dense_dir}\"\n",
    "                        f\" --PatchMatchStereo.max_image_size {args.max_depth_size}\"\n",
    "                        f\" --PatchMatchStereo.window_radius {args.window_radius}\"\n",
    "                        f\" --PatchMatchStereo.geom_consistency {0 if args.fast_depth else 1}\"\n",
    "                        f\" --PatchMatchStereo.window_step {2 if args.fast_depth else 1}\"\n",
    "                        f\" --PatchMatchStereo.num_samples {10 if args.fast_depth else 15}\"\n",
    "                        f\" --PatchMatchStereo.num_iterations {3 if args.fast_depth else 5}\"\n",
    "                        f\" --PatchMatchStereo.cache_size 32\")\n",
    "        if not os.path.isfile(os.path.join(dense_dir, \"fused.ply\")):\n",
    "            pipeline.append(f\"colmap stereo_fusion\"\n",
    "                            f\" --workspace_path {dense_dir}\"\n",
    "                            f\" --input_type {'photometric' if args.fast_depth else 'geometric'}\"\n",
    "                            f\" --output_path {dense_dir}/fused.ply\"\n",
    "                            f\" --StereoFusion.min_num_pixels {args.min_num_pixels}\"\n",
    "                            f\" --StereoFusion.max_image_size {args.max_depth_size}\"\n",
    "                            f\" --StereoFusion.check_num_images {120 * len(args.camera_ids)}\"\n",
    "                            f\" --StereoFusion.cache_size 32\")\n",
    "\n",
    "    if args.mesh:\n",
    "        pipeline.append(f\"colmap poisson_mesher\"\n",
    "                        f\" --input_path {dense_dir}/fused.ply\"\n",
    "                        f\" --output_path {dense_dir}/meshed-poisson.ply\"\n",
    "                        f\" --PoissonMeshing.trim 7\")\n",
    "        pipeline.append(f\"colmap delaunay_mesher\"\n",
    "                        f\" --input_path {dense_dir}\"\n",
    "                        f\" --output_path {dense_dir}/meshed-delaunay.ply\"\n",
    "                        f\" --DelaunayMeshing.quality_regularization 5\"\n",
    "                        f\" --DelaunayMeshing.max_proj_dist 5\")\n",
    "\n",
    "    for step in pipeline:\n",
    "        if args.mask_depth and \"stereo_fusion\" in step:\n",
    "            from read_write_dense import read_array, write_array\n",
    "            for cam_id in args.camera_ids:\n",
    "                os.makedirs(os.path.join(dense_dir, \"masks\", f\"cam{cam_id}\"), exist_ok=True)\n",
    "                os.makedirs(os.path.join(dense_dir, \"stereo\", \"depth_maps_copy\", f\"cam{cam_id}\"), exist_ok=True)\n",
    "                os.makedirs(os.path.join(dense_dir, \"stereo\", \"normal_maps_copy\", f\"cam{cam_id}\"), exist_ok=True)\n",
    "                path = os.path.join(dense_dir, \"stereo\", \"depth_maps\", f\"cam{cam_id}\")\n",
    "                for depth_path in tqdm(glob.glob(os.path.join(path, f\"*{'photometric' if args.fast_depth else 'geometric'}.bin\")),\n",
    "                                       desc=f\"Masking depth [camera {cam_id}/{len(args.camera_ids)}]\"):\n",
    "                    normals_path = depth_path.replace(\"depth_maps\", \"normal_maps\")\n",
    "                    depth_copy_path = depth_path.replace(\"depth_maps\", \"depth_maps_copy\")\n",
    "                    normals_copy_path = normals_path.replace(\"normal_maps\", \"normal_maps_copy\")\n",
    "\n",
    "                    if not os.path.isfile(depth_copy_path) or not os.path.isfile(normals_copy_path):\n",
    "                        if not os.path.isfile(depth_copy_path):\n",
    "                            shutil.copy(depth_path, depth_copy_path)\n",
    "                        if not os.path.isfile(normals_copy_path):\n",
    "                            shutil.copy(normals_path, normals_copy_path)\n",
    "\n",
    "                        depth = read_array(depth_copy_path)\n",
    "                        normals = read_array(normals_copy_path)\n",
    "\n",
    "                        image_name = depth_path.split('/')[-1].split('.')[0] + \".jpg\"\n",
    "                        image_path = os.path.join(dense_dir, \"images\", f\"cam{cam_id}\", image_name)\n",
    "                        mask_path = image_path.replace(\"images\", \"masks\")\n",
    "                        if os.path.isfile(mask_path):\n",
    "                            mask = np.asarray(Image.open(mask_path, formats=[\"JPEG\"]).convert('L'))\n",
    "                        elif \"PINHOLE\" in args.camera_model and args.max_image_size == args.max_depth_size:\n",
    "                            mask_path = os.path.join(all_masks_dir, f\"cam{cam_id}\", image_name + \".png\")\n",
    "                            mask = np.asarray(Image.open(mask_path, formats=[\"PNG\"]).convert('L'))\n",
    "                        else:\n",
    "                            image = Image.open(image_path, formats=[\"JPEG\"])\n",
    "                            if image.size[:2] != depth.shape:\n",
    "                                image.thumbnail(size=(depth.shape[1], depth.shape[0]))\n",
    "                            mask = remove(np.asarray(image),\n",
    "                                          alpha_matting=True,\n",
    "                                          alpha_matting_erode_size=15,\n",
    "                                          only_mask=True)\n",
    "                            Image.fromarray(mask).save(mask_path,\n",
    "                                                       quality=100,\n",
    "                                                       subsampling=0)\n",
    "                        if mask.shape != depth.shape:\n",
    "                            mask = Image.fromarray(mask)\n",
    "                            mask.thumbnail(size=(depth.shape[1], depth.shape[0]))\n",
    "                            mask = np.asarray(mask)\n",
    "\n",
    "                        if depth.shape == normals.shape[:2] == mask.shape:\n",
    "                            depth[mask == 0] = 0\n",
    "                            normals[mask == 0] = 0\n",
    "                            write_array(depth, depth_path)\n",
    "                            write_array(normals, normals_path)\n",
    "                        else:\n",
    "                            print(\"Warning: Mask shape != depth shape\", mask.shape, depth.shape)\n",
    "        subprocess.run(step.split(' '))\n",
    "        if args.mask_depth and \"image_undistorter\" in step and all_masks_dir in step:\n",
    "            shutil.move(os.path.join(dense_dir, \"images\"), os.path.join(dense_dir, \"masks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301cea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = ArgumentParser(description=\"Reconstruct YCB objects from images using photogrammetry.\")\n",
    "    parser.add_argument(\"data_dir\", type=str, help=\"Path to YCB object data directory.\")\n",
    "    parser.add_argument(\"-gh\", \"--colmap_github_dir\", required=True, type=str, help=\"Path to colmap GitHub directory.\")\n",
    "    parser.add_argument(\"--padding\", nargs=4, type=int, default=[150, 150, 150, 150],\n",
    "                        help=\"Padding around existing default object masks.\")\n",
    "    parser.add_argument(\"--max_image_size\", type=int, default=3200, help=\"Maximum image size. Decrease if OOM occurs.\")\n",
    "    parser.add_argument(\"--max_depth_size\", type=int, default=1600,\n",
    "                        help=\"Maximum estimated depth map size.\"\n",
    "                             \"Increase to obtain denser output for weakly textured surfaces.\")\n",
    "    parser.add_argument(\"--window_radius\", type=int, default=10,\n",
    "                        help=\"Stereo reconstruction window size. Increase for weakly textured surfaces.\")\n",
    "    parser.add_argument(\"--min_num_pixels\", type=int, default=10,\n",
    "                        help=\"Minimum allowed number of pixels in stereo fusion. Increase to reduce outliers.\")\n",
    "    parser.add_argument(\"--camera_model\", type=str, default=\"OPENCV\", choices=camera_models.values(),\n",
    "                        help=\"Camera model defining the distortion parameters.\")\n",
    "    parser.add_argument(\"--guided_matching\", type=int, default=True, help=\"Use guided SIFT feature matching.\")\n",
    "    parser.add_argument(\"--ignore_two_view_tracks\", action=\"store_true\", help=\"Enable if sparse model is too noisy.\")\n",
    "    parser.add_argument(\"--estimate_affine_shape\", type=int, default=True, help=\"Estimate affine SIFT features.\")\n",
    "    parser.add_argument(\"--domain_size_pooling\", type=int, default=True, help=\"Use DSP SIFT features.\")\n",
    "    parser.add_argument(\"--data\", action=\"store_true\", help=\"Copy and rename images. Extract masks.\")\n",
    "    parser.add_argument(\"--sparse\", action=\"store_true\", help=\"Perform sparse reconstruction.\")\n",
    "    parser.add_argument(\"--dense\", action=\"store_true\", help=\"Perform dense reconstruction.\")\n",
    "    parser.add_argument(\"--mesh\", action=\"store_true\",\n",
    "                        help=\"Run Poisson surface reconstruction on the dense MVS output.\")\n",
    "    parser.add_argument(\"--fast_depth\", type=int, default=True,\n",
    "                        help=\"Perform fast but potentially less accurate depth estimation.\")\n",
    "    parser.add_argument(\"--mask_depth\", type=int, default=True, help=\"Mask estimated depth maps prior to fusion.\")\n",
    "    parser.add_argument(\"--masked\", action=\"store_true\", help=\"Produce masked images.\")\n",
    "    parser.add_argument(\"--width\", type=int, default=4272, help=\"Image width.\")\n",
    "    parser.add_argument(\"--height\", type=int, default=2848, help=\"Image height.\")\n",
    "    parser.add_argument(\"--update_cameras\", type=int, default=True,\n",
    "                        help=\"Updates camera parameters from calibration data file.\")\n",
    "    parser.add_argument(\"--show_bbox\", action=\"store_true\",\n",
    "                        help=\"Show image cut by bounding box defined by the initial mask and the padding.\")\n",
    "    parser.add_argument(\"--multiple_models\", action=\"store_true\",\n",
    "                        help=\"Allow reconstruction of multiple partial models.\")\n",
    "    parser.add_argument(\"--camera_ids\", nargs='*', type=int, default=[1, 2, 3],\n",
    "                        help=\"Cameras to include in reconstruction.\")\n",
    "    parser.add_argument(\"--show_sparse\", action=\"store_true\", help=\"Visualize sparse model.\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
